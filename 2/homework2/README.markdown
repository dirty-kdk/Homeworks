# Домашнее задание по линейной и логистической регрессии

## Описание
Решение включает модификацию моделей линейной и логистической регрессии, работу с датасетами и эксперименты с гиперпараметрами и feature engineering. Реализованы все требования задания, включая L1/L2 регуляризацию, early stopping, метрики, визуализацию, кастомный датасет, тестирование и логирование.

## Структура проекта
- `homework_model_modification.py`: Модификация моделей с добавлением L1/L2 регуляризации, early stopping, метрик (precision, recall, F1, ROC-AUC) и визуализации матрицы ошибок.
- `homework_datasets.py`: Кастомный класс `CustomCSVDataset` для работы с CSV-файлами, включая нормализацию и кодирование. Эксперименты с произвольным датасетом.
- `homework_experiments.py`: Исследование гиперпараметров и feature engineering на датасете diabetes.
- `tests.py`: Unit-тесты для функций feature engineering.
- `utils.py`: Утилиты для генерации данных, вычисления MSE, логирования эпох и кастомного датасета.
- `data/`: Папка для датасетов
- `models/`: Папка для сохраненных моделей.
- `plots/`: Папка для графиков.

## Результаты
- Модели сохраняются в папку `models/` (например, `model_diabetes_classification.pth`).
- Графики (матрица ошибок, сравнение гиперпараметров, сравнение моделей) сохраняются в папку `plots/`.
- Логирование выводится в консоль и включает информацию о процессе обучения, метриках и сохранении файлов.

## Анализ вывода
- **Линейная регрессия**: Модель обучилась на 200 примерах с потерей, снизившейся с 2853.54 до 76.9 к эпохе 28 (early stopping). Результат можно улучшить, уменьшив скорость обучения (lr=0.1).
- **Логистическая регрессия (diabetes)**: Модель обучилась на 768 примерах датасета diabetes с потерей, снизившейся с 0.6739 до 0.5346 за 100 эпох. Модель сохранена в `models/logreg_diabetes.pth`. Потеря указывает на улучшение по сравнению с случайным угадыванием (0.693).
- **Логистическая регрессия (предыдущая)**: Модель обучилась на 200 примерах с 4 признаками и 3 классами. Потеря снизилась с 1.2881 до 0.7671 к эпохе 50. Метрики: Precision 0.7996, Recall 0.8000, F1 0.7992, ROC-AUC 0.9240. Матрица ошибок показывает правильные предсказания (48, 54, 58) и ошибки (7, 10).
- **Логистическая регрессия (эксперименты с гиперпараметрами)**: На датасете diabetes (768 примеров) были проведены 27 экспериментов с комбинациями learning_rat {0.001, 0.01, 0.1}, batch_size {16, 32, 64} и оптимизаторами SGD, Adam, RMSprop. Потери снижались от 0.6739 до диапазона [0.5192–0.5242] при лучших конфигурациях. Лучшая комбинация: optimizer=Adam, learning_rate=0.01, batch_size=16, потеря к 50-й эпохе — 0.5195 Почти идентичный результат показал RMSprop с теми же параметрами — 0.5201. Хуже всего себя показал SGD с lr=0.001, batch_size=64 — потеря оставалась выше 0.64. Вывод: Adam и RMSprop + learning_rate=0.01 + batch_size=16 — оптимальные гиперпараметры для логистической регрессии на этом датасете
